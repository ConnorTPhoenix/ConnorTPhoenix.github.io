---
layout: post
title: 2/8/2017
---
# Billboard 100 (2000)

## Introduction
In this second project for General Assembly's Data Science Immersive program I investigated the music of the 2000s. Specifically, I analyzed songs from the Billboard Hot 100 which peaked in the year 2000. My goal was to perform exploratory data analysis in order to better understand what makes a particular song reach the top of the charts.

## The Data
The dataset is taken from Billboard.com and provides a complete list of songs that peaked on the Billboard Hot 100 in the year 2000. Attributes of the dataset include Artist Name, Track Name, Song Length, Genre, Date Entered, Date Peaked, and a column for each week with a corresponding ranking.

The raw data was in .csv file format. I read in the source file to a (317 x 83) pandas dataframe. The resulting columns were all object data types with the exception of year (int64) and x1st.week (int64). See data dictionary below:

| Attribute | Type|
| :-------------: |:-------------:|
year              |   int64
artist.inverted   |  object
track             | object
time              | object
genre             | object
date.entered      | object
date.peaked       | object
x1st.week         | int64
x2nd.week ....    | object
x65th.week        | object

## Data Cleaning
### Column Names
In order to get the dataset into a more useable format I first modified the column headers. This focused around making the column names more readable. I also wanted to make the weekly ranking columns (i.e. x1st.week) more concise.

    bb.columns = [x.replace('x','') for x in bb.columns]
    bb.columns = [x.replace('week','wk') for x in bb.columns]
    bb = bb.rename(columns={'artist_inverted': 'artist'})
    bb = bb.rename(columns={'time': 'song_length_(s)'})
    bb.columns = [x.replace('.',' _ ') for x in bb.columns]

### Nan Values
After looking at the head of the dataframe I noted that a large portion of the weekly ranking columns contained the string " * " as a value. I replaced these values with NaN using the follow function:  

    def insert_nans(value):
      if value == ' * ':
        return np.nan
      else:
        return value

     bb = bb.applymap(insert_nans)

This allowed me to identify any columns that contained all NaN values. I removed the from the data set as follows:

    bb.dropna(axis='columns',how='all', inplace=True)

I then wanted to convert the weekly rank columns back to numerical values. I replaced all remaining NaN values with 0s using the follow function:

    def replace_nans(value):
      if pd.isnull(value):
        value = 0
      else:
        value=value
      return value

    bb = bb.applymap(replace_nans)

This allowed me to then convert all the weekly rank columns to data type 'integer' as follows:

    bb.iloc[:,7:] = bb.iloc[:,7:].astype(int)

## Time Attributes

The billboard dataset contained 3 time related columns as data type 'object' ('song_length_(s)', 'date_entered', and 'date_peaked'). These columns needed to be converted to be more usuable.

converted 'song_length_(s)' to seconds as data type 'integer':

    def convert_song_length(value):
      value = value.split(',')
      value = [int(value[i]) for i in range(0,2)]
      value = value[0] * 60 + value[1]
      value = pd.to_timedelta(value, unit='s')
      return value

    bb['song_length_(s)'] = bb['song_length_(s)'].apply(convert_song_length)
    bb['song_length_(s)'] = bb['song_length_(s)'].astype(int)
    bb['song_length_(s)'] = bb['song_length_(s)']//1000000000

## Assumptions  

* 'Rock' and 'Rock'n'roll' are two distinct music genres.




## Exploratory Analysis


## Data Visualization

## Hypothesis Testing
